# Take-Home Coding Challenge

### Demo üì∑
<h1 align="center">
  <img alt='logo' title='logo' src='images/logo_gif.gif'>
</h1>

# Tabela de conteudos  
- [Take-Home Coding Challenge](#take-home-coding-challenge)
    - [Demo üì∑](#demo-)
- [Tabela de conteudos](#tabela-de-conteudos)
  - [Sobre o projeto](#sobre-o-projeto)
  - [Tecnologias](#tecnologias)
  - [Servi√ßos utilizados](#servi√ßos-utilizados)
- [Explica√ß√£o do c√≥digo](#explica√ß√£o-do-c√≥digo)
  - [1 - Primeira parte (request/parse/soup, title, brand, categories, description)](#1---primeira-parte-requestparsesoup-title-brand-categories-description)
  - [2 - Segunda parte (sku)](#2---segunda-parte-sku)
    - [2.1 - Parte 1](#21---parte-1)
    - [2.2 - Parte 2](#22---parte-2)
  - [3 - Terceira parte (properties)](#3---terceira-parte-properties)
  - [4 - Quarta parte (reviews)](#4---quarta-parte-reviews)
  - [5 - Quinta parte (review_average_score, url)](#5---quinta-parte-review_average_score-url)
  - [6 - Sexta parte ()](#6---sexta-parte-)
  - [Finalidades](#finalidades)
  - [Links](#links)
  - [Considera√ß√µes finais](#considera√ß√µes-finais)
  - [Autor](#autor)
  
---

## Sobre o projeto 

Esse projeto √© parte do processo seletivo para a empresa Infosimples, empresa especializada em desenvolvimento de projetos de Web Scraping e Intelig√™ncia Artificial. O projeto se baseia no scraping de uma p√°gina web projetada para simular um e-commerce, possuindo uma vitrine de produtos com diversas caracter√≠sticas, como T√≠tulo, Categoria, Pre√ßo, etc. O objetivo do projeto √© realizar o scraping dessas caracter√≠sticas encontradas na p√°gina para ent√£o salva-las em um arquivo "produtos.json".

---

## Tecnologias 

Aqui est√£o as tecnologias usadas nesse projeto.

* Python version  3.10.4
* Visual Studio Code
* Anaconda 

---

## Servi√ßos utilizados

* Github

---

# Explica√ß√£o do c√≥digo

## 1 - Primeira parte (request/parse/soup, title, brand, categories, description)
Imports, Requisi√ß√£o HTTP, utiliza√ß√£o do html.parser, instanceamento do objeto soup a partir da classe BeaultifulSoup() e defini√ß√£o de algumas fun√ß√µes que extraem determinados dados da p√°gina. A maior complexidade nessa parte do c√≥digo se da  na fun√ß√£o get_description() onde eu utilizo regex para limpar algumas sujeiras do texto coletado, como '\n' e espa√ßos duplicados.

<h2 align="center">
  <img alt='logo' title='logo' src='images/parte_1.png'>
</h2>

---

## 2 - Segunda parte (sku)
Definindo a fun√ß√£o que ira me retornar uma lista contendo as informa√ß√µes do sku.
A fun√ß√£o a seguir ficou muito grande ent√£o dividi em dois prints para melhor visualiza√ß√£o.

  ### 2.1 - Parte 1 
  H√° alguns produtos que possuem um valor para a tag (div class='sku-current-price') enquanto um outro retorna null (porque ele esta fora de estoque), ent√£o para evitar erros, eu utilizei uma condi√ß√£o if para verificar se a busca por essa tag retornava algum valor ou n√£o e com base nisso fazer um append para a lista que ir√° conter os valores, sendo preenchida com 'None' caso n√£o possua um valor para current_price. E eu tamb√©m fiz uma limpeza dos dados retirando o cifr√£o e convertendo a string para float.

  A mesma l√≥gica foi utilizada para old_price !!

  <h2 align="center">
  <img alt='logo' title='logo' src='images/parte_2.1.png'>
  </h2>
  
  ### 2.2 - Parte 2
  2.2.1- Para saber se o produto estava disponivel ou n√£o em estoque eu percebi que existia uma tag (meta itemprop='availability') que possui um par√¢metro chamado content onde se encontra um link em que o endpoint dele √© o indicativo para se existe o produto est√° ou n√£o disponivel em estoque. Coletei todas essas tags e utilizei uma regex para excluir todas as tags em que possuem o endpoint do par√¢metro como "NewCondition" pois isso atrapalharia meu racioc√≠nio  seguinte.<br>
  2.2.2 - Agora com uma lista contendo apenas as tags desejadas, eu apliquei uma regex onde ela selecionava a primeira palavra do endpoint, caso ela fosse I significa que estava em estoque, porque vinha de "InStock", caso n√£o fosse I a primeira letra, ent√£o vinha de 'OutOfStock', logo n√£o estava em estoque.<br>
  2.2.3 - Fiz a chamada das fun√ß√µes internas da fun√ß√£o get_sku() para atribuir √†s vari√°veis e armazena-las em um dicion√°rio o qual atribui para ser o retorno da fun√ß√£o.

  <h2 align="center">
  <img alt='logo' title='logo' src='images/parte_2.2.png'>
  </h2>

---

## 3 - Terceira parte (properties)
Aviso!! A mesma l√≥gica para get_product_properties() √© a de get_additional_properties(). Definindo a fun√ß√£o que coleta as propriedades do produto. Bem, essa parte eu fiquei muito em d√∫vida se eu retornaria duas listas, uma contendo todas as labels, e na outra os textos dessas labels, ou se era tudo em uma lista s√≥. Por√©m ambos os formatos pareciam ruins e n√£o leg√≠veis para mim, ent√£o como eu estou acostumado a utilizar a biblioteca pandas e visualizar tabelas como dicion√°rios, eu coletei as propriedades dessa forma, fazendo chave: valor para label: text. A l√≥gica foi de coletar o texto da primeira tag 'pure-table pure-table-bordered' e fazer uma limpeza nele, utilizando o split('\n') para eliminar as sujeiras e um filter para retirar os valores nulos que ficaram no lugar dos \n deixado pelo split. Ent√£o eu recebia como sa√≠da dessa coleta uma lista contendo todas as informa√ß√µes da tabela, por√©m de forma unidimensional e intercalada onde os index √≠mpares eram os textos e os pares as labels, e seguindo essa l√≥gica eu utilizei uma condi√ß√£o onde se o index fosse impar ele coletava esse elemento para uma lista que armazenava os textos e se fosse par armazenava para labels. Com as duas listas finalizadas eu criava um dicion√°rio onde ele atribui chave:valor para o os elementos com mesma posi√ß√£o na lista.
<br> O retorno era : [Color, Various, Material, Rubber, Shape, Ducky, Size, Medium, Weight, 1.5 Kg, Radioactivity Level, Low]<br>
Eu fiz: <br>
labels = [Color, Material, Shape, Size, Weight, Radioactivity Level]<br>
text = [Various, Rubber, Ducky, Medium, 1.5 kg, Low]

Ent√£o utilizei a fun√ß√£o zip() para criar o dicion√°rio com elas.

Com os dicion√°rios feitos (Um para product_properties e outro para additional_properties (pois sao 2 tabelas diferentes)) eu inseri eles em uma lista e retornei como valor da fun√ß√£o.

Obs1: A fun√ß√£o zip cria um objeto zip em memoria onde ele assimila 2 elementos de dois iter√°veis com base nos seus √≠ndices serem iguais. E depois eu converti esse objeto em mem√≥ria para um dicion√°rio.<br>
Obs2: Para get_additional_properties() eu fiz um pop para dropar o cabe√ßalho que foi coletado da tabela e n√£o era de interesse. E uma limpeza para retirar o caractere ¬∫ pois estava dando problema de enconding.


<h2 align="center">
  <img alt='logo' title='logo' src='images/parte_3.png'>
</h2>

## 4 - Quarta parte (reviews)
4.1- A fun√ß√£o get_reviews() coleta as informa√ß√µes a respeito dos reviews e armazena em uma lista. Dentro de get_reviews() na fun√ß√£o get_name() eu tentei utilizar o encode("iso-8859-1").decode('utf-8') para trata o problema de enconding que estava tendo na sa√≠da por causa de acentos no nome do Kairo Josu√©, dentro do programa deu certo, caso voc√™ printe os nomes, por√©m depois quando salvou no arquivo produtos.json voltou a dar problema, mas deixei assim. Pois foi bom eu ter utilizado nesse primeiro momento essa t√©cnica do enconding, j√° que ela que me levou a conseguir resolver o problema de como coletar as avalia√ß√µes das estrelas.<br>
 4.2 - **get_stars()** essa foi a parte mais dif√≠cil em quest√£o de l√≥gica dentro do c√≥digo para mim. Depois de estudar um pouco e ver alguns v√≠deos, eu utilizei os m√©todos encode("iso-8859-1").decode('utf-8') e descobri um padr√£o, o padr√£o era que '√¢\x98\x85' significava uma estrela preenchida, ou seja, positiva, ent√£o eu defini que positive_star = '√¢\x98\x85'.encode("iso-8859-1").decode('utf-8'), ent√£o no la√ßo for para percorrer todas as avalia√ß√µes coletadas eu utilizei o m√©todo count() onde eu recebo como retorno a quantidade de vezes em que a estrela positiva foi encontrada em cada avalia√ß√£o!!!<br>
  4.3- Para coleta dos textos, apenas utilizei o encode para evitar erros com acentos. Por√©m como aconteceu nom os nomes, quando salvo no arquivo produtos.json acabou dando problema novamente. 4.4- Com todos os dados coletados, eu chamei as fun√ß√µes e retornei seus valores, e armazenei em um dicion√°rio como retorno de get_reviews()

<h2 align="center">
  <img alt='logo' title='logo' src='images/parte_4.png'>
</h2>


---

## 5 - Quinta parte (review_average_score, url)
5.1- A fun√ß√£o get_revies_average_score() utiliza de um regex para retirar apenas o n√∫mero e fazer um cast para o tornar inteiro.<br>
5.2- A fun√ß√£o get_url() coleta as urls, sem complexidade<br>
5.3- √â definido ent√£o a resposta_final(), recebendo todos os valores para a cria√ß√£o do dicion√°rio e posterior escrita do arquivo produtos.json

<h2 align="center">
  <img alt='logo' title='logo' src='images/parte_5.png'>
</h2>


---

## 6 - Sexta parte ()
Essa √© a parte onde eu realizo a chamada de todas as fun√ß√µes para o script, √© onde eu coloquei o c√≥digo em produ√ß√£o. Provavelmente pode haver algum erro ou m√° pratica, por√©m eu ainda estou estudando e aprendendo sobre ETL, e esse √© o corpo que ele ficou, com isso o c√≥digo est√° funcionando normalmente e modularizado. 

<h2 align="center">
  <img alt='logo' title='logo' src='images/parte_6.png'>
</h2>

---

## Finalidades
As principais finalidade dessa aplica√ß√£o s√£o:
 - Raspagem de dados de um website 
 - Armazenar os dados coletados em um arquivo JSON

---

## Links
  - Repositorio: https://github.com/Junior-Prestes-Nogueira/Infosimples_case

---

## Considera√ß√µes finais
Durante todo o pensamento anal√≠tico para cria√ß√£o desse c√≥digo, eu tive a ideia  que deveria realizar um scraping para uma p√°gina n√£o est√°tica e que poderia receber mudan√ßas o tempo todo, como altera√ß√£o no valor dos produtos, pre√ßos, descri√ß√£o, etc. Tanto que eu comecei a fazer o projeto pensando em ter como sa√≠da um arquivo produtos.json contendo um objeto json para cada produto, tendo chave:valor sendo representado por id do produto e seu conte√∫do de caracteristicas, porem eu acabei n√£o fazendo assim por incerteza se seria recusado por conta do modelo de sa√≠da ser diferente. 

--- 

## Autor

**Junior Prestes Nogueira** 

Obrigado pela aten√ß√£o e pela oportunidade de resolver o case!!

---